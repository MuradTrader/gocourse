## Объяснение по тексту:

### 1. Что такое горутины?

Горутины (go routines) — это легковесные потоки, управляемые средой выполнения Go. Они позволяют конкурентное выполнение функций, что даёт возможность выполнять несколько задач одновременно в одной программе на Go. Это одна из ключевых особенностей Go, которая делает написание конкурентных и параллельных программ простым.

### 2. Как создать горутину?

Используем ключевое слово `go` перед функцией:

```go
package main

import (
    "fmt"
    "time"
)

func sayHello() {
    time.Sleep(1 * time.Second)
    fmt.Println("Hello from goroutine")
}

func main() {
    go sayHello()
}
```

**Результат в консоли:**

```
(ничего не выводится)
```

### 3. Почему нет вывода?

Когда мы запускаем горутину с ключевым словом `go`, функция извлекается из главного потока и выполняется в фоновом режиме. Главная функция (main) завершается раньше, чем горутина успевает выполниться, поэтому программа завершается без вывода.

### 4. Как дождаться завершения горутины?

Простой способ — использовать `time.Sleep`:

```go
func main() {
    fmt.Println("Beginning program")
    go sayHello()
    fmt.Println("After sayHello function")
    time.Sleep(2 * time.Second)
}
```

**Результат в консоли:**

```
Beginning program
After sayHello function
Hello from goroutine
```

### 5. Как работает выполнение?

1. Печатается "Beginning program"
2. Горутина `sayHello` запускается и уходит в фоновый режим
3. Сразу печатается "After sayHello function" (неблокирующее выполнение)
4. Программа ждет 2 секунды
5. Горутина завершает ожидание 1 секунду и печатает "Hello from goroutine"
6. Программа завершается

### 6. Еще пример с двумя горутинами:

```go
func printNumbers() {
    for i := 0; i < 5; i++ {
        fmt.Println(i)
        time.Sleep(100 * time.Millisecond)
    }
}

func printLetters() {
    for _, letter := range "ABCDE" {
        fmt.Println(string(letter))
        time.Sleep(200 * time.Millisecond)
    }
}

func main() {
    fmt.Println("Beginning program")
    go sayHello()
    fmt.Println("After sayHello function")

    go printNumbers()
    go printLetters()

    time.Sleep(2 * time.Second)
}
```

**Примерный результат в консоли (может меняться):**

```
Beginning program
After sayHello function
A
0
1
B
2
3
C
4
D
E
Hello from goroutine
```

### 7. Планировщик горутин

Go использует модель планирования M:N, где M горутин отображаются на N потоков операционной системы. Планировщик эффективно мультиплексирует горутины на доступных потоках, переключая их по мере необходимости.

### 8. Обработка ошибок в горутинах:

```go
func doWork() error {
    time.Sleep(1 * time.Second)
    return fmt.Errorf("an error occurred in doWork")
}

func main() {
    var err error

    go func() {
        err = doWork()
    }()

    time.Sleep(2 * time.Second)

    if err != nil {
        fmt.Println("Error:", err)
    } else {
        fmt.Println("Work completed successfully")
    }
}
```

**Результат в консоли:**

```
Error: an error occurred in doWork
```

### 9. Конкурентность vs Параллелизм

- **Конкурентность**: Множество задач выполняются одновременно, но не обязательно в одно и то же время
- **Параллелизм**: Задачи выполняются буквально в одно и то же время на нескольких процессорах

Горутины обеспечивают конкурентность, а среда выполнения Go планирует их на доступных CPU для параллелизма, когда это возможно.

### 10. Частые проблемы и лучшие практики:

1. **Утечки горутин**: Главная функция завершается до завершения горутин
2. **Бесконечные циклы** в горутинах
3. **Избыточное создание горутин** может привести к исчерпанию ресурсов
4. Используйте **worker pools** для контроля количества активных горутин
5. Реализуйте **обработку ошибок** внутри горутин
6. Используйте **примитивы синхронизации** (sync.WaitGroup, sync.Mutex) для координации горутин

Горутины — это просто функции с ключевым словом `go` перед ними. Они выполняются независимо и конкурентно, не блокируя основной поток выполнения программы.

`============================================================================`

## Шаг 1: Что такое горутина?

**Горутина** - это как маленький работник внутри вашей программы.

- Обычно программа работает **последовательно**: сначала одна задача, потом другая.
- С горутинами программа может работать **параллельно**: несколько задач одновременно.

**Пример из жизни:**
Представьте, что вы готовите завтрак:

- Без горутин: сначала жарите яичницу (ждете 3 минуты), потом готовите кофе (ждете 2 минуты) - всего 5 минут.
- С горутинами: одновременно ставите жариться яичницу И готовить кофе - всего 3 минуты.

## Шаг 2: Базовый код без горутин

Давайте посмотрим на простой код:

```go
package main

import (
    "fmt"
    "time"
)

func sayHello() {
    time.Sleep(1 * time.Second)  // Ждем 1 секунду
    fmt.Println("Hello from goroutine")
}

func main() {
    sayHello()  // Просто вызываем функцию
}
```

**Что происходит:**

1. Программа начинает выполнять `main()`
2. Вызывается функция `sayHello()`
3. Программа останавливается на 1 секунду (`time.Sleep`)
4. Печатается "Hello from goroutine"
5. Программа завершается

**Результат в консоли (через 1 секунду):**

```
Hello from goroutine
```

## Шаг 3: Добавляем горутину (КЛЮЧЕВОЙ МОМЕНТ!)

Теперь добавим волшебное слово `go`:

```go
func main() {
    go sayHello()  // Добавили "go" перед вызовом функции
}
```

**Что происходит теперь:**

1. Программа начинает выполнять `main()`
2. Видит `go sayHello()` - это специальная команда
3. **Главный поток программы** (main) говорит: "Я не буду ждать эту функцию, пусть она работает где-то в фоне"
4. Главный поток сразу идет дальше
5. Но в `main()` больше ничего нет, поэтому программа **сразу завершается**
6. Функция `sayHello()` даже не успевает начать работу

**Результат в консоли:**

```
(ничего не выводится, программа сразу завершается)
```

**Визуализация:**

```
Время 0: main() начинает работу
Время 0: main() видит "go sayHello()"
Время 0: main() говорит: "Эй, sayHello, работай в фоне!"
Время 0: main() смотрит - дальше ничего нет
Время 0: main() завершает программу
Время 0: sayHello() только собирается начать, но программа уже умерла
```

## Шаг 4: Как заставить программу ждать горутину?

Нужно дать время горутине выполниться. Самый простой способ - заставить главную программу подождать:

```go
func main() {
    fmt.Println("Beginning program")  // Шаг 1
    go sayHello()                     // Шаг 2
    fmt.Println("After sayHello function")  // Шаг 3
    time.Sleep(2 * time.Second)       // Шаг 4
}
```

**Что происходит по шагам:**

**Шаг 1:**

```
Консоль: Beginning program
Объяснение: Это обычная команда печати, выполняется сразу
```

**Шаг 2:**

```
Консоль: (ничего)
Объяснение: Запускается горутина sayHello()
Главная программа НЕ ждет, она сразу идет к следующей строке
sayHello() начинает работать в фоне (спит 1 секунду)
```

**Шаг 3:**

```
Консоль: After sayHello function
Объяснение: Главная программа сразу печатает это, не дожидаясь sayHello()
```

**Шаг 4:**

```
Консоль: (ничего)
Объяснение: Главная программа засыпает на 2 секунды
В это время в фоне:
- sayHello() спит 1 секунду
- После 1 секунды сна sayHello() печатает свое сообщение
```

**Шаг 5:**

```
Консоль: Hello from goroutine
Объяснение: Это напечатала горутина sayHello() после своего сна
```

**Шаг 6:**

```
Программа ждет еще 1 секунду (всего 2 секунды сна) и завершается
```

**Полный результат в консоли:**

```
Beginning program        (сразу)
After sayHello function  (сразу)
Hello from goroutine     (через 1 секунду)
(программа завершается через 2 секунды от начала)
```

## Шаг 5: Почему порядок такой?

Давайте добавим временные метки, чтобы увидеть точнее:

```go
func main() {
    fmt.Println(time.Now(), "Beginning program")
    go sayHello()
    fmt.Println(time.Now(), "After sayHello function")
    time.Sleep(2 * time.Second)
    fmt.Println(time.Now(), "Program ending")
}

func sayHello() {
    fmt.Println(time.Now(), "sayHello: starting sleep")
    time.Sleep(1 * time.Second)
    fmt.Println(time.Now(), "sayHello: Hello from goroutine")
}
```

**Примерный результат:**

```
2024-01-01 10:00:00.000 Beginning program
2024-01-01 10:00:00.000 After sayHello function
2024-01-01 10:00:00.000 sayHello: starting sleep
2024-01-01 10:00:01.000 sayHello: Hello from goroutine
2024-01-01 10:00:02.000 Program ending
```

**Видим, что:**

1. Все начинается в одно время (10:00:00)
2. Горутина сразу начинает работать
3. Главная программа не ждет горутину
4. Через 1 секунду горутина печатает сообщение
5. Еще через 1 секунду программа завершается

## Шаг 6: Несколько горутин - почему порядок хаотичный?

```go
func printNumbers() {
    for i := 0; i < 3; i++ {
        fmt.Println("Number:", i)
        time.Sleep(100 * time.Millisecond)
    }
}

func printLetters() {
    for _, letter := range "ABC" {
        fmt.Println("Letter:", string(letter))
        time.Sleep(200 * time.Millisecond)
    }
}

func main() {
    go printNumbers()  // Горутина 1
    go printLetters()  // Горутина 2
    time.Sleep(1 * time.Second)
}
```

**Возможные результаты в консоли (каждый раз разные!):**

**Вариант 1:**

```
Number: 0
Letter: A
Number: 1
Number: 2
Letter: B
Letter: C
```

**Вариант 2:**

```
Letter: A
Number: 0
Letter: B
Number: 1
Number: 2
Letter: C
```

**Почему так происходит?**

Представьте, что у вас есть 2 повара (горутины) и 1 плита (процессор):

- Повар 1 (printNumbers) делает блюдо за 100 мс
- Повар 2 (printLetters) делает блюдо за 200 мс
- Они работают одновременно, но плита только одна
- Плита переключается между поварами
- Мы не знаем, кого плита обслужила первой

**Таймлайн (примерный):**

```
0 мс: Начинают работать оба повара
0 мс: Плита выбирает повара 1 → "Number: 0"
100 мс: Плита выбирает повара 2 → "Letter: A"
200 мс: Повар 1 готов → "Number: 1"
300 мс: Повар 2 готов → "Letter: B"
400 мс: Повар 1 готов → "Number: 2"
600 мс: Повар 2 готов → "Letter: C"
```

## Шаг 7: Ключевые выводы

1. **`go` = "работай в фоне"**

   - Когда пишем `go функция()`, программа не ждет эту функцию
   - Программа сразу идет к следующей строке

2. **Главная программа должна ждать**

   - Если главная программа (main) завершится, все горутины умрут
   - Нужно давать время горутинам (time.Sleep, waitgroups, channels)

3. **Порядок непредсказуем**

   - Горутины работают параллельно
   - Мы не знаем, какая горутина закончит первой
   - Компьютер сам решает, как распределять время

4. **Горутины легковесные**
   - Можно создавать тысячи горутин
   - Они работают эффективнее, чем потоки в других языках

## Самый простой способ понять:

Представьте, что вы - руководитель (главная программа), а горутины - ваши сотрудники:

**Без горутин:**

- Вы говорите сотруднику: "Сделай задачу А"
- Ждете, пока он сделает
- Потом говорите: "Теперь сделай задачу Б"

**С горутинами:**

- Вы говорите сотруднику: "Сделай задачу А (иди работай в другом кабинете)"
- Сразу говорите другому сотруднику: "Сделай задачу Б (иди в третий кабинет)"
- Вы ждете 2 часа (time.Sleep)
- За это время оба сотрудника работают параллельно
- Через 2 часа вы проверяете результаты

Если вы уйдете с работы (программа завершится) через 5 минут, то не дождетесь результатов от сотрудников, которые работают по 1 часу.

`============================================================================`

## Шаг 1: Как работают обычные потоки (в других языках)

**Без горутин** (Java, C++, Python с потоками):

1. Каждый поток = отдельный поток операционной системы (OS thread)
2. Каждый поток имеет свой стек (обычно 1-8 МБ памяти)
3. Переключение между потоками делается операционной системой (медленно)
4. Создать 1000 потоков = нагрузка на ОС

## Шаг 2: Как работают горутины

**Горутины** - это не потоки ОС! Это пользовательские потоки, которыми управляет Go runtime.

### Архитектура "M:N" (M горутин на N потоков ОС)

```
[Горутина 1] [Горутина 2] ... [Горутина 1000]
       ↓           ↓                 ↓
    [Go Runtime (Планировщик)]
       ↓           ↓                 ↓
[Поток ОС 1] [Поток ОС 2] ... [Поток ОС 4]
       ↓           ↓                 ↓
[ Ядро 1  ] [ Ядро 2  ] ... [ Ядро 4  ]
```

## Шаг 3: Ключевые компоненты Go runtime

### 1. **M (Machine)** - Поток операционной системы

- Настоящий поток ОС (как в других языках)
- Выполняется на ядре процессора
- В Go их обычно столько же, сколько логических ядер процессора
- Пример: 8 ядер → примерно 8 потоков ОС

### 2. **G (Goroutine)** - Горyтина

- Легковесная сущность (2 КБ стека в начале)
- Содержит: код функции, стек, текущую позицию выполнения
- Может быть в состояниях: выполняется, ожидает, готово

### 3. **P (Processor)** - Контекст планировщика

- Связывает M и G
- Имеет локальную очередь горутин
- Количество P = GOMAXPROCS (обычно равно количеству ядер)

## Шаг 4: Как выполняется код на процессоре

### Пример 1: Простая программа

```go
func main() {
    go task1()  // Горутина 1
    go task2()  // Горутина 2
    task3()     // Основной поток
}
```

**Что происходит на уровне процессора:**

1. **Запуск программы:**

```
CPU Ядро 1: [M1-P1] выполняет main() как горутину
```

2. **Создание горутин:**

```
CPU Ядро 1: [M1-P1] создает G1 (task1) и G2 (task2)
Очередь P1: [G1, G2] (локальная очередь)
```

3. **Планировщик Go решает, что выполнять:**

```
CPU Ядро 1: [M1-P1] берет G1 из очереди
CPU Ядро 1: выполняет task1() на ядре 1
```

4. **Если есть другие ядра:**

```
CPU Ядро 2: [M2-P2] простаивает
Планировщик может передать G2 на P2
CPU Ядро 2: [M2-P2] начинает выполнять task2()
```

## Шаг 5: Прерывания и переключения

Горутины **кооперативные**, а не вытесняющие (в основном). Это значит:

### Когда горутина добровольно уступает место:

1. **Вызов `time.Sleep()`**

   ```go
   time.Sleep(100 * time.Millisecond)
   // Горутина говорит: "Я посплю, выполни других"
   ```

2. **Операции с каналами**

   ```go
   ch <- data  // Отправка в канал
   data := <-ch  // Получение из канала
   // Если канал не готов, горутина ждет
   ```

3. **Системные вызовы** (файлы, сеть)

   ```go
   file.Read()  // Ожидание диска
   http.Get()   // Ожидание сети
   ```

4. **Вызов `runtime.Gosched()`**
   ```go
   runtime.Gosched()  // Явно уступить место
   ```

### Как происходит переключение:

```
[CPU Ядро 1]
1. Горутина G1 выполняет time.Sleep(1 second)
2. Go runtime фиксирует: "G1 будет спать"
3. Сохраняет контекст G1 (регистры, стек указатель)
4. Берет следующую горутину из очереди P1 (например, G2)
5. Восстанавливает контекст G2
6. Продолжает выполнение G2
Время переключения: ~100-200 наносекунд (в 10 раз быстрее, чем переключение потоков ОС)
```

## Шаг 6: Стек горутин (почему они легкие)

### Поток ОС (другие языки):

```
Стек: 1-8 МБ фиксированного размера
Создание: выделяет всю память сразу
```

### Горутина Go:

```
Начальный стек: 2 КБ (в 4000 раз меньше!)
Растущий стек: увеличивается по мере необходимости
Копирование стека: при росте данные копируются в новый больший стек
```

**Почему это важно:**

- 1000 потоков ОС = 8 ГБ памяти (8 МБ × 1000)
- 1000 горутин = 2 МБ памяти (2 КБ × 1000) + немного на рост

## Шаг 7: Пример с системными вызовами

```go
func main() {
    go downloadFile("file1.txt")  // Горутина 1
    go processData()              // Горутина 2

    time.Sleep(5 * time.Second)
}

func downloadFile(filename string) {
    // 1. Системный вызов: ожидание сети/диска
    data, _ := os.ReadFile(filename)  // БЛОКИРУЮЩИЙ ВЫЗОВ

    // 2. Когда данные пришли, горутина снова готова
    fmt.Println("Downloaded", len(data), "bytes")
}
```

**Что происходит на уровне процессора:**

```
CPU Ядро 1: [M1-P1-G1] начинает downloadFile()
CPU Ядро 1: G1 делает системный вызов os.ReadFile()
Операционная система: "Эй, Go, твой поток будет ждать диск"
Go runtime: "Хорошо, я откреплю M1 от G1"

[ПЕРЕПЛАНИРОВАНИЕ]
Go runtime: Берет свободный поток ОС M2
Go runtime: Прикрепляет M2 к P1
CPU Ядро 1: [M2-P1-G2] начинает выполнять processData()

[КОГДА ДАННЫЕ ГОТОВЫ]
Операционная система: "Данные готовы!"
Go runtime: Находит свободный поток ОС M3
Go runtime: Продолжает выполнение G1 на M3
CPU Ядро 2: [M3-P2-G1] продолжает downloadFile()
```

## Шаг 8: Work-stealing (воровство работы)

Если один процессор (P) простаивает, он может "украсть" работу у другого:

```
P1: [G1, G2, G3, G4]  // Много работы
P2: []                 // Нет работы

P2: "У P1 много работы, украду половину!"
P2 забирает G3 и G4 из очереди P1
Теперь:
P1: [G1, G2]
P2: [G3, G4]

Оба ядра процессора работают эффективно!
```

## Шаг 9: Практический пример с числами

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func worker(id int) {
    for i := 0; i < 3; i++ {
        // Симулируем работу
        sum := 0
        for j := 0; j < 1000000; j++ {
            sum += j * j
        }
        fmt.Printf("Worker %d: iteration %d, sum = %d\n", id, i, sum)
        time.Sleep(10 * time.Millisecond)  // Уступаем место
    }
}

func main() {
    // Узнаем сколько ядер
    fmt.Println("CPU cores:", runtime.NumCPU())
    fmt.Println("GOMAXPROCS:", runtime.GOMAXPROCS(0))

    // Запускаем горутин больше, чем ядер
    for i := 0; i < 10; i++ {
        go worker(i)
    }

    time.Sleep(2 * time.Second)
}
```

**Что происходит внутри:**

```
CPU cores: 8
GOMAXPROCS: 8  // 8 потоков ОС будет создано

На уровне процессора:
1. Go runtime создает 8 потоков ОС (M)
2. Создает 8 контекстов планировщика (P)
3. Привязывает каждый M к P
4. Распределяет 10 горутин по 8 очередям P
5. Каждый P выполняет свои горутины на своем M
6. Когда горутина sleep или завершается, P берет следующую

Визуализация выполнения:
CPU Ядро 1: [Worker 0] → sleep → [Worker 8]
CPU Ядро 2: [Worker 1] → sleep → [Worker 9]
CPU Ядро 3: [Worker 2] → ...
...
```

## Шаг 10: Ключевые отличия от потоков ОС

| Аспект           | Поток ОС        | Горутина            |
| ---------------- | --------------- | ------------------- |
| **Создание**     | 1-10 мс         | 0.1-0.5 мс          |
| **Память**       | 1-8 МБ          | 2-8 КБ              |
| **Переключение** | 1-10 мкс        | 0.1-0.5 мкс         |
| **Планировщик**  | Ядро ОС         | Go runtime          |
| **Параллелизм**  | Да              | Да                  |
| **Вытеснение**   | Да (прерывания) | Нет (кооперативное) |

## Итог простыми словами:

1. **Go runtime** - это как диспетчер на складе
2. **Горутины** - это как рабочие задания (коробки)
3. **Потоки ОС (M)** - это как погрузчики
4. **Процессоры (P)** - это как рабочие станции

**Алгоритм работы:**

1. У вас есть 1000 заданий (горутин)
2. Есть 8 погрузчиков (потоков ОС)
3. Диспетчер (Go runtime) дает задания погрузчикам
4. Когда погрузчик ждет (например, ждет грузовик), диспетчер дает ему другое задание
5. В итоге все 8 погрузчиков всегда заняты
6. 1000 заданий выполняются быстро, хотя погрузчиков всего 8

**На процессоре это выглядит так:**

- Каждое ядро постоянно выполняет инструкции
- Go runtime быстро переключает между горутинами
- Процессор не простаивает в ожидании I/O
- Все ядра загружены равномерно

Вот почему Go такой эффективный для одновременного выполнения множества задач!

`============================================================================`

## Краткий ответ:

**Одно ядро процессора = ОДИН поток ОС (M) в данный момент времени.** Go не может создать M2 внутри CPU Ядро 1, пока M1 работает. Но Go может быстро переключать горутины **на одном ядре**!

## Подробное объяснение:

### Шаг 1: Начальная ситуация

```
CPU Ядро 1: [M1-P1] выполняет G1
CPU Ядро 2: [M2-P2] простаивает (или выполняет что-то другое)
CPU Ядро 3: [M3-P3] простаивает
CPU Ядро 4: [M4-P4] простаивает
```

### Шаг 2: Что может делать Go runtime?

**Вариант А: Если G1 заблокировался (например, sleep, ожидание I/O)**

```go
func G1() {
    time.Sleep(1 * time.Second)  // Блокирующая операция
    // или
    data := <-someChannel  // Ожидание данных
}
```

```
Ситуация:
1. G1 вызывает time.Sleep()
2. M1 (поток ОС) все еще привязан к ядру 1
3. Go runtime говорит: "M1 будет спать в ОС? Нет, это неэффективно!"
4. Go runtime открепляет M1 от P1 (но M1 все еще существует)
5. P1 теперь свободен, но у него нет потока ОС
6. Go runtime создает или берет свободный M5
7. Прикрепляет M5 к P1
8. Теперь M5 начинает выполнять другую горутину из очереди P1 (например, G2)
9. M1 ждет в ОС, пока не пройдет 1 секунда

Результат:
CPU Ядро 1: [M5-P1] выполняет G2 (теперь M5 на ядре 1 вместо M1)
```

**Вариант Б: Если G1 выполняет вычисления (CPU-bound)**

```go
func G1() {
    for i := 0; i < 1000000000; i++ {
        // Тяжелые вычисления
    }
}
```

```
Ситуация:
1. G1 выполняет тяжелые вычисления
2. M1 продолжает работать на ядре 1
3. Другие горутины (G2, G3, G4) ждут в очереди P1
4. Go 1.14+ имеет вытесняющую многозадачность
5. Через ~10 мс Go runtime посылает сигнал прерывания
6. M1 приостанавливает G1, сохраняет контекст
7. M1 берет следующую горутину из очереди P1 (G2)
8. M1 продолжает работать на ядре 1, но теперь выполняет G2
```

### Шаг 3: Может ли быть два потока ОС (M) на одном ядре?

**Технически - НЕТ, в один момент времени.**

Но практически - ДА, за счет быстрого переключения (context switching):

```
Время     CPU Ядро 1        Что происходит
0-1 мс    [M1] выполняет G1   M1 работает
1-2 мс    [M2] выполняет G2   Планировщик ОС переключил M2 на ядро 1
2-3 мс    [M1] выполняет G3   Снова переключение
```

**Это делает планировщик ОС, а не Go runtime!**

### Шаг 4: Что делает Go runtime с P (процессорами)?

По умолчанию: `GOMAXPROCS = количество ядер CPU`

```
4 ядра = 4 P (P1, P2, P3, P4)
Каждому P привязан M (поток ОС)
Но количество M может быть БОЛЬШЕ, чем количество P!
```

### Шаг 5: Практический пример

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func main() {
    // Показываем начальные настройки
    fmt.Printf("Ядер CPU: %d\n", runtime.NumCPU())
    fmt.Printf("GOMAXPROCS: %d\n", runtime.GOMAXPROCS(0))

    // Запускаем много горутин
    for i := 1; i <= 8; i++ {
        go worker(i)
    }

    time.Sleep(3 * time.Second)

    // Смотрим статистику
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    fmt.Printf("\nГорутин создано: ~%d\n", m.NumGC) // грубая оценка
}

func worker(id int) {
    fmt.Printf("Worker %d начал на P\n", id)

    if id == 1 {
        // Первый воркер делает блокирующую операцию
        time.Sleep(2 * time.Second)
    } else {
        // Остальные делают вычисления
        sum := 0
        for i := 0; i < 100000000; i++ {
            sum += i * i
        }
    }

    fmt.Printf("Worker %d завершил\n", id)
}
```

### Шаг 6: Что происходит внутри (визуализация)

```
Начало программы:
CPU Ядро 1: [M1-P1] выполняет main(), затем запускает worker(1)
CPU Ядро 2: [M2-P2] запускает worker(2)
CPU Ядро 3: [M3-P3] запускает worker(3)
CPU Ядро 4: [M4-P4] запускает worker(4)

worker(5), worker(6), worker(7), worker(8) ждут в очередях P

Через 0.1 секунды:
worker(1) вызывает time.Sleep(2 секунды)

Что происходит:
1. M1 блокируется в ОС (ждет 2 секунды)
2. Go runtime: "P1 теряет поток M1!"
3. Go runtime создает новый поток ОС M5
4. M5 прикрепляется к P1
5. M5 берет worker(5) из очереди P1
6. Теперь на CPU Ядро 1 работает M5 (а не M1)

Еще через 10 мс:
worker(2) на CPU Ядро 2 выполняет тяжелые вычисления
Go runtime посылает сигнал прерывания
worker(2) приостанавливается
M2 берет worker(6) из очереди P2
```

### Шаг 7: Статистика в реальном времени

Давайте добавим отслеживание:

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func monitor() {
    for {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)

        fmt.Printf("\n=== Мониторинг ===")
        fmt.Printf("\nГорутин: %d", runtime.NumGoroutine())
        fmt.Printf("\nПотоков ОС: ??? (Go не предоставляет API для этого)")
        fmt.Printf("\nВыполняется: ???")

        time.Sleep(500 * time.Millisecond)
    }
}

func main() {
    go monitor()

    // Запускаем смесь горутин
    for i := 0; i < 20; i++ {
        go func(id int) {
            if id%2 == 0 {
                // Блокирующие операции
                time.Sleep(time.Duration(id%5+1) * time.Second)
            } else {
                // Вычисления
                sum := 0
                for j := 0; j < 10000000; j++ {
                    sum += j * j
                }
            }
            fmt.Printf("Горутина %d завершена\n", id)
        }(i)
    }

    time.Sleep(10 * time.Second)
}
```

### Шаг 8: Ключевые выводы

1. **Одно ядро = один активный поток ОС в момент времени**

   - Физическое ограничение процессора

2. **Go может создавать больше потоков ОС (M), чем ядер**

   - Например, 4 ядра, но 10 потоков ОС
   - Это нужно для блокирующих операций

3. **Переключение происходит на нескольких уровнях:**

   - Уровень 1: Go runtime переключает горутины на одном M (быстро, ~100 нс)
   - Уровень 2: Go runtime переключает M на P (при блокировках)
   - Уровень 3: ОС переключает M между ядрами (медленно, ~1-10 мкс)

4. **Идеальная ситуация:**

   ```
   CPU Ядро 1: M1-P1 [G1, G5, G9]  ← переключает Go runtime
   CPU Ядро 2: M2-P2 [G2, G6, G10] ← переключает Go runtime
   CPU Ядро 3: M3-P3 [G3, G7, G11] ← переключает Go runtime
   CPU Ядро 4: M4-P4 [G4, G8, G12] ← переключает Go runtime

   M5, M6, M7: ждут в пуле (на случай блокировок)
   ```

5. **Если все горутины вычисляющие (CPU-bound):**

   - 4 ядра → максимум 4 горутины работают параллельно
   - Остальные ждут
   - Переключение происходит каждые ~10 мс (вытеснение)

6. **Если горутины много I/O (блокирующие):**
   - Go создает дополнительные потоки ОС
   - Может быть больше активных потоков, чем ядер
   - ОС быстро переключает их на ядрах

### Шаг 9: Аналогия из реальной жизни

Представьте **4 станка (ядра CPU)** на фабрике:

**Сценарий 1: Только вычисления (CPU-bound)**

- У вас 8 рабочих заданий (горутин)
- Но только 4 станка
- Каждый станок обрабатывает по 1 заданию за раз
- Если задание сложное (10 минут), другие ждут
- Диспетчер (Go runtime) может переключить задание через 1 минуту

**Сценарий 2: Много ожидания (I/O-bound)**

- Задания часто требуют ждать (ждать детали, ждать краску)
- Когда рабочий ждет, он идет к другому станку
- Так 4 станка могут обслуживать 20 рабочих
- Потому что большую часть времени рабочие ждут, а не работают

**Вот так Go использует ядра CPU!**

`============================================================================`

## Представь, что твой компьютер - это **кухня**, а процессор - это **плита**.

### Базовая аналогия:

1. **Ядро процессора** = **1 конфорка на плите**

   - У тебя 4 конфорки (4 ядра)
   - Каждая конфорка готовит только **1 блюдо** в один момент

2. **Поток ОС (M)** = **1 кастрюля/сковорода**

   - На конфорку можно поставить 1 кастрюлю
   - В кастрюле может быть разная еда

3. **Горутина (G)** = **рецепт блюда**

   - Рецепт может быть коротким или длинным
   - Нужно выполнять шаги по порядку

4. **Go планировщик** = **повар-диспетчер**
   - Управляет, что готовить, где и когда
   - Быстро переключается между рецептами

## Теперь твой вопрос:

У тебя 4 конфорки (ядра) и 4 рецепта (G1, G2, G3, G4).

### Сценарий 1: Простое приготовление

```
Конфорка 1: Кастрюля M1, готовит G1 (рецепт 1)
Конфорка 2: Кастрюля M2, готовит G2 (рецепт 2)
Конфорка 3: Кастрюля M3, готовит G3 (рецепт 3)
Конфорка 4: Кастрюля M4, готовит G4 (рецепт 4)

Все работает параллельно! Каждая конфорка готовит свое.
```

### Сценарий 2: Ожидание (например, ждем кипения)

G1 говорит: "Мне нужно ждать 5 минут, пока закипит вода"

Что делает повар-диспетчер (Go):

```
Конфорка 1: M1 ждет кипения (бездействует)
Вместо того чтобы ждать, повар берет новую кастрюлю M5
Ставит M5 на ту же Конфорку 1
В M5 начинает готовить G5 (новый рецепт)
Когда вода в M1 закипела, повар возвращает M1 на Конфорку 1
```

**Но!** Нельзя поставить **две кастрюли одновременно** на одну конфорку!

Что происходит на самом деле:

```
Секунда 0-1: Конфорка 1 готовит M1 (G1)
Секунда 1-2: Конфорка 1 готовит M5 (G5)  ← быстро переключили!
Секунда 2-3: Конфорка 1 снова готовит M1 (G1) ← снова переключили!
```

### Сценарий 3: Много быстрых задач

Представь, что у тебя:

- 4 конфорки
- 10 маленьких рецептов (каждый по 30 секунд)

Повар-диспетчер (Go) делает так:

```
Конфорка 1: Рецепт 1 → Рецепт 5 → Рецепт 9
Конфорка 2: Рецепт 2 → Рецепт 6 → Рецепт 10
Конфорка 3: Рецепт 3 → Рецепт 7
Конфорка 4: Рецепт 4 → Рецепт 8
```

Все готовится почти одновременно, потому что повар быстро переключается!

## Технически, как это работает:

### 1. **Одно ядро = одна активная "кастрюля" (поток ОС) в момент времени**

- Физически нельзя на одном ядре выполнять две инструкции от разных потоков одновременно

### 2. **Но переключение происходит ОЧЕНЬ быстро!**

```
1 секунда = 1 000 000 000 наносекунд
Переключение между горутинами: 100-200 наносекунд
Переключение между потоками ОС: 1000-10000 наносекунд
```

### 3. **Go оптимизирует это:**

- Использует **свои горутины** вместо потоков ОС
- Переключает горутины быстрее, чем ОС переключает потоки
- Создает дополнительные потоки ОС только когда нужно (например, при ожидании диска)

## Простой пример кода:

```go
func main() {
    // Запускаем 8 горутин на 4 ядрах
    for i := 1; i <= 8; i++ {
        go cook(i)
    }

    time.Sleep(5 * time.Second)
}

func cook(recipeNumber int) {
    fmt.Printf("Начинаю рецепт %d\n", recipeNumber)
    time.Sleep(2 * time.Second)  // "Жду кипения"
    fmt.Printf("Закончил рецепт %d\n", recipeNumber)
}
```

### Что происходит внутри:

```
У тебя 4 конфорки (ядра)
Задачи:
Рецепт 1, 2, 3, 4, 5, 6, 7, 8

Повар Go распределяет:
Конфорка 1: Рецепт 1 → Рецепт 5
Конфорка 2: Рецепт 2 → Рецепт 6
Конфорка 3: Рецепт 3 → Рецепт 7
Конфорка 4: Рецепт 4 → Рецепт 8

Все рецепты начинают готовиться почти сразу!
```

## Ответ на твой вопрос:

**Q:** Может ли Go создать M2 внутри CPU Ядро 1, пока там работает M1?
**A:** **НЕТ, не может одновременно.** Но может переключить M2 на это ядро вместо M1!

**Q:** Или Go переключится к CPU Ядро 2 чтобы создать M2-P2?
**A:** **ДА, если ядро 2 свободно.** Go попробует использовать свободные ядра сначала.

## Ключевое правило:

**1 ядро = 1 активный поток ОС в конкретный момент**

**НО!** За 1 секунду ядро может обработать:

- Несколько потоков ОС (переключаясь между ними)
- Сотни горутин (Go переключает их еще быстрее)

## Визуализация за 1 секунду:

```
Ядро 1: [M1-G1] → [M1-G5] → [M5-G9] → [M1-G1] → ...
       ↑         ↑         ↑         ↑
    переключение горутин и потоков

За 1 секунду одно ядро может "поработать" с десятками разных горутин!
```

**Вывод:** Хотя физически на одном ядре в один момент выполняется только одна инструкция одного потока, быстрые переключения создают иллюзию параллельного выполнения множества задач. Go делает эти переключения очень эффективно!

`============================================================================`

## Представь, что ты - **студент, который готовится к экзаменам**.

### Конкурентность (Concurrency) - **ОДИН студент, МНОГО предметов**

У тебя есть:

- Математика
- История
- Физика
- Литература

**Как ты готовишься КОНКУРЕНТНО:**

```
18:00-18:15 → Математика (15 минут)
18:15-18:30 → История (15 минут)
18:30-18:45 → Физика (15 минут)
18:45-19:00 → Литература (15 минут)
19:00-19:15 → Снова Математика (15 минут)
...
```

**Что происходит:**

- Ты **ОДИН человек** (одно ядро процессора)
- Ты **быстро переключаешься** между предметами
- Со стороны кажется, что ты учишь всё **одновременно**
- Но на самом деле в **конкретный момент** ты учишь только **один предмет**

**Результат за вечер:** ты немного продвинулся в каждом предмете.

### Параллелизм (Parallelism) - **НЕСКОЛЬКО студентов, МНОГО предметов**

У тебя есть 4 друга:

- Андрей (математика)
- Борис (история)
- Виктор (физика)
- Григорий (литература)

**Как вы готовитесь ПАРАЛЛЕЛЬНО:**

```
18:00-19:00: Андрей → Математика (60 минут)
              Борис → История (60 минут)
              Виктор → Физика (60 минут)
              Григорий → Литература (60 минут)
```

**Что происходит:**

- **4 человека** (4 ядра процессора)
- Каждый учит свой предмет **одновременно** с другими
- В момент времени 18:30 **все 4 предмета** изучаются сразу

**Результат за час:** каждый предмет изучен глубоко.

## Техническая аналогия:

### Конкурентность (1 ядро)

```
CPU Ядро 1: [G1] → [G2] → [G3] → [G1] → [G2] ...
Время:    0мс   10мс   20мс   30мс   40мс
```

- **Переключение:** быстрое (миллисекунды/наносекунды)
- **Иллюзия:** все работает одновременно
- **Реальность:** в конкретный наносекундный момент выполняется только одна задача

### Параллелизм (4 ядра)

```
CPU Ядро 1: [G1] [G1] [G1] [G1] [G1] ...
CPU Ядро 2: [G2] [G2] [G2] [G2] [G2] ...
CPU Ядро 3: [G3] [G3] [G3] [G3] [G3] ...
CPU Ядро 4: [G4] [G4] [G4] [G4] [G4] ...
Время:    0мс - все 4 задачи выполняются ОДНОВРЕМЕННО!
```

- **Реальность:** 4 задачи выполняются в один и тот же момент

## Пример из жизни:

### Ситуация: Ты готовишь завтрак

1. **Жаришь яичницу** (3 минуты)
2. **Готовишь кофе** (2 минуты)
3. **Готовишь тосты** (1 минута)

**Конкурентно (ты один):**

```
0-1 мин: Начинаешь жарить яичницу
1-2 мин: Пока яичница жарится, ставишь кофе
2-3 мин: Пока кофе готовится, делаешь тосты
3-4 мин: Завершаешь яичницу
4-5 мин: Завершаешь кофе
```

**Итог:** 5 минут, всё готово. Ты делал всё "одновременно", но на самом деле переключался.

**Параллельно (с женой/мужем):**

```
Ты:       0-3 мин → жаришь яичницу
Супруг:   0-2 мин → готовит кофе
          2-3 мин → делает тосты
```

**Итог:** 3 минуты, всё готово. Вы делали всё **буквально одновременно**.

## Как это относится к Go?

```go
func main() {
    // Конкурентность: запускаем много горутин
    go task1()  // Горутина 1
    go task2()  // Горутина 2
    go task3()  // Горутина 3
    go task4()  // Горутина 4

    time.Sleep(2 * time.Second)
}
```

### Если у тебя 1 ядро:

```
CPU Ядро 1: [task1] → [task2] → [task3] → [task4] → [task1] ...
            ↑         ↑         ↑         ↑         ↑
        быстрое переключение (конкурентность)
```

### Если у тебя 4 ядра:

```
CPU Ядро 1: [task1] [task1] [task1] ...  ← параллельно!
CPU Ядро 2: [task2] [task2] [task2] ...  ← параллельно!
CPU Ядро 3: [task3] [task3] [task3] ...  ← параллельно!
CPU Ядро 4: [task4] [task4] [task4] ...  ← параллельно!
```

## Простая программа для демонстрации:

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func worker(id int) {
    for i := 0; i < 5; i++ {
        fmt.Printf("Worker %d: шаг %d\n", id, i)
        time.Sleep(100 * time.Millisecond)
    }
}

func main() {
    // Узнаем сколько ядер
    cores := runtime.NumCPU()
    fmt.Printf("У тебя %d ядер процессора\n", cores)

    // Запускаем 8 работников
    for i := 1; i <= 8; i++ {
        go worker(i)
    }

    time.Sleep(2 * time.Second)
}
```

### Что ты увидишь:

**Если 1 ядро (старый компьютер):**

```
Worker 1: шаг 0
Worker 2: шаг 0
Worker 3: шаг 0
Worker 4: шаг 0
Worker 5: шаг 0
...
```

Работники выполняются **по очереди, но быстро** (конкурентность).

**Если 8 ядер (новый компьютер):**

```
Worker 1: шаг 0  ← все эти 8 строк
Worker 2: шаг 0  ← появляются почти
Worker 3: шаг 0  ← одновременно!
Worker 4: шаг 0
Worker 5: шаг 0
Worker 6: шаг 0
Worker 7: шаг 0
Worker 8: шаг 0
```

Работники выполняются **буквально одновременно** (параллелизм).

## Ключевые отличия в таблице:

|                   | Конкурентность             | Параллелизм                    |
| ----------------- | -------------------------- | ------------------------------ |
| **Кто выполняет** | Один исполнитель           | Несколько исполнителей         |
| **Как выполняет** | Быстро переключается       | Выполняют одновременно         |
| **Нужно**         | Много задач, одно ядро     | Много задач, много ядер        |
| **Пример**        | Один повар готовит 3 блюда | 3 повара готовят 3 блюда       |
| **В Go**          | Горутины на одном ядре     | Горутины распределены по ядрам |
| **Результат**     | Кажется, что всё сразу     | Всё действительно сразу        |

## Самый простой способ запомнить:

- **Конкурентность** = **быстрое переключение** (как жонглер - кажется, что все мячи в воздухе одновременно, но в руке всегда один)
- **Параллелизм** = **одновременное выполнение** (как оркестр - все музыканты играют одновременно)

**Горутины в Go дают тебе и то, и другое:**

1. Ты пишешь код с горутинами (получаешь конкурентность)
2. Go runtime сам решает, как их распределить по ядрам (чтобы получить параллелизм, если ядра есть)

**Вывод:**

- **Конкурентность** - это про **дизайн программы** (как ты организуешь код)
- **Параллелизм** - это про **выполнение** (как процессор выполняет твой код)

Ты пишешь конкурентный код (с горутинами), а Go пытается выполнить его параллельно (если есть несколько ядер).

`============================================================================`

## Правильное понимание:

### 1. **Вычислительные задачи (CPU-bound)**

```go
func calculate() {
    // Много математики, без ожидания
    for i := 0; i < 1000000000; i++ {
        result += i * i
    }
}
```

**Что делает Go runtime:**

```
M1-P1 на Ядре 1: [G1] → [G2] → [G3] ...
                 ↑     ↑     ↑
           Go runtime переключает горутины
```

**Go runtime переключает горутины (G) на одном M!**

### 2. **I/O задачи (блокирующие)**

```go
func readFile() {
    data, _ := os.ReadFile("file.txt")  // Ждем диск
    // или
    resp, _ := http.Get("https://...")  // Ждем сеть
}
```

**Что делает Go runtime:**

```
M1-P1 на Ядре 1: G1 вызывает os.ReadFile()
Операционная система: "Диск будет готов через 10 мс"
Go runtime: "М1 будет ждать? Неэффективно!"
Go runtime: Открепляет M1 от P1
M1 ждет в ОС (блокируется)
Go runtime: Берет новый/свободный M2
Go runtime: Прикрепляет M2 к P1
M2 начинает выполнять G2 из очереди P1
```

**Ключевой момент:** Когда M блокируется на I/O, **Go runtime открепляет M от P и прикрепляет другой M**!

## Правильная таблица:

| Тип задачи               | Кто переключает     | Что переключается                |
| ------------------------ | ------------------- | -------------------------------- |
| **Вычислительная (CPU)** | **Go runtime**      | Горутины (G) на одном M          |
| **I/O (блокирующая)**    | **Go runtime + ОС** | Потоки ОС (M) на Процессорах (P) |

## Простая аналогия:

### Сценарий: Ты - директор фабрики (Go runtime), у тебя рабочие (M) и станки (P)

#### 1. Рабочие делают расчеты (CPU-bound)

```
Рабочий М1 на Станке P1:
8:00 - Считает задачу G1
8:01 - Директор: "Переключись на задачу G2!"
8:01 - Рабочий М1 теперь считает G2
8:02 - Директор: "Вернись к задаче G1!"
```

**Директор (Go runtime)** переключает **задачи** у одного рабочего.

#### 2. Рабочий ждет грузовик (I/O-bound)

```
Рабочий М1 на Станке P1:
8:00 - Ждет грузовик с деталями (блокировка)
8:00 - Директор: "Ты будешь ждать! Освободи станок!"
8:00 - Рабочий М1 уходит ждать грузовик
8:00 - Директор зовет Рабочего М2
8:00 - Рабочий М2 встает к Станку P1
8:00 - Рабочий М2 начинает делать задачу G2
```

**Директор (Go runtime)** меняет **рабочих** на станке.

## Технически точно:

### Для CPU-bound задач:

```
Уровень 1: Go runtime scheduler
Что делает: Переключает горутины (G) в очереди одного P
Когда: При вызове функций, в циклах, каждые 10мс
Кто: Только Go runtime, ОС не участвует
```

### Для I/O-bound задач:

```
Уровень 1: ОС (операционная система)
Что делает: Блокирует поток ОС (M) при системном вызове
Когда: При чтении файла, ожидании сети, sleep

Уровень 2: Go runtime scheduler
Что делает: Видит, что M блокируется, открепляет M от P
Когда: Сразу при блокировке M
Кто: Go runtime реагирует на блокировку ОС
```

## Пример кода для понимания:

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func cpuTask(id int) {
    fmt.Printf("CPU task %d started\n", id)
    // Много вычислений
    sum := 0
    for i := 0; i < 100000000; i++ {
        sum += i * i
    }
    fmt.Printf("CPU task %d finished\n", id)
}

func ioTask(id int) {
    fmt.Printf("IO task %d started\n", id)
    // Ожидание (имитация I/O)
    time.Sleep(2 * time.Second)
    fmt.Printf("IO task %d finished\n", id)
}

func main() {
    // Запускаем смесь задач
    go cpuTask(1)  // Вычислительная
    go ioTask(2)   // I/O задача
    go cpuTask(3)  // Вычислительная
    go ioTask(4)   // I/O задача

    // Даем время на выполнение
    time.Sleep(5 * time.Second)

    // Смотрим статистику
    fmt.Printf("\nАктивных горутин: %d\n", runtime.NumGoroutine())
}
```

## Что происходит внутри (упрощенно):

### Для `cpuTask(1)`:

```
1. G1 (cpuTask1) попадает в очередь P1
2. M1 берет G1 и начинает выполнение на Ядре 1
3. Go runtime переключает M1 между G1 и другими CPU-задачами
```

### Для `ioTask(2)`:

```
1. G2 (ioTask2) попадает в очередь P1
2. M1 берет G2
3. G2 вызывает time.Sleep() → системный вызов
4. ОС: "Поток M1 будет ждать 2 секунды"
5. Go runtime: "Откреплю M1 от P1"
6. Go runtime берет M2 из пула, прикрепляет к P1
7. M2 начинает выполнять следующую горутину
8. Через 2 секунды ОС разблокирует M1
9. Go runtime прикрепляет M1 к свободному P (или тому же P1)
10. G2 продолжает выполнение
```

## Ключевые выводы:

1. **Для CPU задач**: Go runtime переключает **горутины (G)** на одном **потоке ОС (M)**
2. **Для I/O задач**:

   - Сначала **ОС** блокирует **поток ОС (M)**
   - Затем **Go runtime** открепляет **M** от **процессора (P)**
   - **Go runtime** прикрепляет другой **M** к **P**

3. **Go runtime всегда активен** в управлении, даже при I/O
4. **ОС участвует только в блокировке/разблокировке потоков**

## Самый простой способ запомнить:

- **CPU задача** = **быстрое переключение между задачами** у одного работника
- **I/O задача** = **замена работника**, когда тот ушел ждать грузовик

**В обоих случаях директор (Go runtime) управляет процессом!**

`============================================================================`

Да — **всё работает реально на одном физическом ядре. И вот почему это так мощно.**

Представь:

```
1 CPU core
GOMAXPROCS = 1   →   1 P
```

Это означает:

```
P1
 └─ M1
     └─ G1, G2, G3, G4, ... G100000
```

---

# Что реально происходит

## 1. CPU-задачи

На одном ядре:

- M1 крутит **тысячи горутин по тайм-слайсам**
- Это userspace-переключение
- Без syscalls
- Очень дешёво

=> ты можешь держать **десятки тысяч активных задач** на одном ядре.

---

## 2. I/O задачи (магия)

Допустим:

```
M1+P1 исполняет G42
G42 делает read() с сокета → ядро блокирует M1
```

Что делает Go:

```
P1 мгновенно отцепляется от M1
P1 → прикрепляется к M2 (новому OS thread)
M2 начинает крутить G43, G44, G45
```

**Физически ядро то же самое**, но:

| Было                      | Стало                 |
| ------------------------- | --------------------- |
| M1 завис в ядре           | M2 работает           |
| программа не остановилась | все G продолжают жить |

ОС просто переключает потоки **внутри того же ядра**.

---

# Ключевая мысль

> Даже на 1 ядре Go умеет делать:
>
> • 100k сетевых соединений
> • 100k горутин
> • тысячи одновременных запросов
> **без потери производительности**

потому что он **не держит ядро в блоке**, когда один syscall завис.

---

# Почему Node и Java тут проигрывают

| Язык | 1 ядро + 100k sockets           |
| ---- | ------------------------------- |
| Node | один event loop → лаги          |
| Java | 100k threads → смерть по памяти |
| Go   | 100k goroutines → нормально     |

---

Ты сейчас понимаешь фундамент того, **почему Go — это серверный язык №1 для бирж, крипты, realtime.**
